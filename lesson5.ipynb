{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson5.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "rVU0B2pk7sBi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# from theano.sandbox import cuda\n",
        "# Skip GPU check\n",
        "# esnure GPU is on on colab..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FNMc1H_zOIQ5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68e9e04a-74d2-458f-ad19-e17531fce2a6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226144839,
          "user_tz": -330,
          "elapsed": 2707,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install bcolz"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bcolz in /usr/local/lib/python2.7/dist-packages\r\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python2.7/dist-packages (from bcolz)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IDYXKtpP7sB1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "#import utils; reload(utils)\n",
        "#from utils import *\n",
        "# check if you need utils down there...\n",
        "from __future__ import division, print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iUl_5PtsBlVn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# DO it the hard way.. \n",
        "# Import things as you need.. so that you know what you are importing..\n",
        "# rahter than importing the whole utils.py file.. an dbeing clueless about where this fn came from \n",
        "import numpy as np\n",
        "import os, re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U0GFRCcC7sB6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model_path = 'data/imdb/models/'\n",
        "%mkdir -p $model_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pRJOjSR7sB9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup data"
      ]
    },
    {
      "metadata": {
        "id": "D537_Gd_7sB-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Going to look at the IMDB dataset, which contains movie reviews from IMDB, along with their sentiment.  \n",
        "Keras comes with some helper functions for this dataset."
      ]
    },
    {
      "metadata": {
        "id": "-koGQWI87sB-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import imdb\n",
        "idx = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pAdeoEGH7sCB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is the word list:"
      ]
    },
    {
      "metadata": {
        "id": "Hjy1QRvp_dxJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17e3c172-6b67-441c-d569-d56afc05f091",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226150190,
          "user_tz": -330,
          "elapsed": 776,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "type(idx)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "metadata": {
        "id": "1kQKjfq97sCB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ca31f31-6f54-4a64-939b-1d65a378eca0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226151032,
          "user_tz": -330,
          "elapsed": 698,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "idx_arr = sorted(idx, key=idx.get)\n",
        "idx_arr[:10]\n",
        "#u is for unicode"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'the', u'and', u'a', u'of', u'to', u'is', u'br', u'in', u'it', u'i']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "metadata": {
        "id": "TL5Fx9c17sCG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "...and this is the mapping from id to word"
      ]
    },
    {
      "metadata": {
        "id": "ATTzyEkA7sCH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "idx2word = {v: k for k, v in idx.iteritems()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ALRg43mx9BQw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c89a5188-0825-41ac-bd9d-baeb7fc6712b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226152726,
          "user_tz": -330,
          "elapsed": 811,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "type(idx2word)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "metadata": {
        "id": "gW_rlDft9jef",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dacadf0-6459-4416-d52d-2512e77af0cd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226153562,
          "user_tz": -330,
          "elapsed": 750,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "first2pairs = {k: idx2word[k] for k in idx2word.keys()[:2]}\n",
        "first2pairs"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: u'the', 2: u'and'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "metadata": {
        "id": "qOmS2God7sCK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We download the reviews using code copied from keras.datasets:  \n",
        "There no neater nack to do this.."
      ]
    },
    {
      "metadata": {
        "id": "JYncn1aK7sCM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# part of utils\n",
        "from keras.utils.data_utils import get_file\n",
        "import pickle\n",
        "#end of part of utils\n",
        "\n",
        "path = get_file('imdb_full.pkl',\n",
        "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
        "                md5_hash='d091312047c43cf9e4e38fef92437263') # cool.. very with an md5 hash :D\n",
        "f = open(path, 'rb')\n",
        "(x_train, labels_train), (x_test, labels_test) = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zN1HUoTrAI7r",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d4f644ce-d8d8-434d-b4d1-f39a1f3ffc92",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226175666,
          "user_tz": -330,
          "elapsed": 803,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "type(x_train)\n",
        "isinstance(x_train, list)\n",
        "isinstance(x_train[0][0], int)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "w6iC2RHVANkj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65b3893f-0a11-4490-b1c5-30338dd4ca27",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226250613,
          "user_tz": -330,
          "elapsed": 1155,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "x_train[0][0:3]"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[23022, 309, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "metadata": {
        "id": "rHr4dl1J7sCR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44c74cca-7938-439e-df03-c4620b877b20",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226177349,
          "user_tz": -330,
          "elapsed": 743,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "metadata": {
        "id": "XAHwFBnb7sCU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's the 1st review. As you see, the words have been replaced by ids. The ids can be looked up in idx2word."
      ]
    },
    {
      "metadata": {
        "id": "yRsroL1C7sCV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cc3127dc-1985-49a4-8d35-3904c1f4fa5b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226178213,
          "user_tz": -330,
          "elapsed": 784,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "', '.join(map(str, x_train[0]))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'23022, 309, 6, 3, 1069, 209, 9, 2175, 30, 1, 169, 55, 14, 46, 82, 5869, 41, 393, 110, 138, 14, 5359, 58, 4477, 150, 8, 1, 5032, 5948, 482, 69, 5, 261, 12, 23022, 73935, 2003, 6, 73, 2436, 5, 632, 71, 6, 5359, 1, 25279, 5, 2004, 10471, 1, 5941, 1534, 34, 67, 64, 205, 140, 65, 1232, 63526, 21145, 1, 49265, 4, 1, 223, 901, 29, 3024, 69, 4, 1, 5863, 10, 694, 2, 65, 1534, 51, 10, 216, 1, 387, 8, 60, 3, 1472, 3724, 802, 5, 3521, 177, 1, 393, 10, 1238, 14030, 30, 309, 3, 353, 344, 2989, 143, 130, 5, 7804, 28, 4, 126, 5359, 1472, 2375, 5, 23022, 309, 10, 532, 12, 108, 1470, 4, 58, 556, 101, 12, 23022, 309, 6, 227, 4187, 48, 3, 2237, 12, 9, 215'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "metadata": {
        "id": "LvRbqcTt7sCc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first word of the first review is 23022. Let's see what that is."
      ]
    },
    {
      "metadata": {
        "id": "kaRCUwRG7sCc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcd45d15-486c-46da-be92-8185708e3f1e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226179100,
          "user_tz": -330,
          "elapsed": 801,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "idx2word[23022] # idx2word is a dict that has the mappings"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "u'bromwell'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "metadata": {
        "id": "UgzioOP17sCg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here's the whole review, mapped from ids to words."
      ]
    },
    {
      "metadata": {
        "id": "pnUiIwzG7sCg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b8bb3b76-06dc-4db0-962b-ff77a9848b45",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226179969,
          "user_tz": -330,
          "elapsed": 787,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "' '.join([idx2word[o] for o in x_train[0]])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "u\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "metadata": {
        "id": "IVM-5ryA7sCj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The labels are 1 for positive, 0 for negative."
      ]
    },
    {
      "metadata": {
        "id": "Bc6ORhZS7sCk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "811ff658-9caa-4f65-aed8-3591ad030f49",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226180816,
          "user_tz": -330,
          "elapsed": 726,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "labels_train[:10]"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "metadata": {
        "id": "IzSaVZq57sCp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reduce vocab size by setting rare words to max index."
      ]
    },
    {
      "metadata": {
        "id": "pAKwS4ug7sCq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = 5000\n",
        "\n",
        "trn = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_train]\n",
        "test = [np.array([i if i<vocab_size-1 else vocab_size-1 for i in s]) for s in x_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FYyv1gH1B7yh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "343ed748-d4b7-4e79-fc62-08a5620e0da0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226184365,
          "user_tz": -330,
          "elapsed": 786,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "trn[0] # so the rarer words are all set to 4999"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4999,  309,    6,    3, 1069,  209,    9, 2175,   30,    1,  169,\n",
              "         55,   14,   46,   82, 4999,   41,  393,  110,  138,   14, 4999,\n",
              "         58, 4477,  150,    8,    1, 4999, 4999,  482,   69,    5,  261,\n",
              "         12, 4999, 4999, 2003,    6,   73, 2436,    5,  632,   71,    6,\n",
              "       4999,    1, 4999,    5, 2004, 4999,    1, 4999, 1534,   34,   67,\n",
              "         64,  205,  140,   65, 1232, 4999, 4999,    1, 4999,    4,    1,\n",
              "        223,  901,   29, 3024,   69,    4,    1, 4999,   10,  694,    2,\n",
              "         65, 1534,   51,   10,  216,    1,  387,    8,   60,    3, 1472,\n",
              "       3724,  802,    5, 3521,  177,    1,  393,   10, 1238, 4999,   30,\n",
              "        309,    3,  353,  344, 2989,  143,  130,    5, 4999,   28,    4,\n",
              "        126, 4999, 1472, 2375,    5, 4999,  309,   10,  532,   12,  108,\n",
              "       1470,    4,   58,  556,  101,   12, 4999,  309,    6,  227, 4187,\n",
              "         48,    3, 2237,   12,    9,  215])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "metadata": {
        "id": "OleQemQ67sCs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Look at distribution of lengths of sentences."
      ]
    },
    {
      "metadata": {
        "id": "7XQXS3Ok7sCt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cd985fe-db4e-4256-b3ea-8ea4040a7686",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226185199,
          "user_tz": -330,
          "elapsed": 753,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "lens = np.array(map(len, trn))\n",
        "(lens.max(), lens.min(), lens.mean())"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2493, 10, 237.71364)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "metadata": {
        "id": "PuX29JyW7sCw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pad (with zero) or truncate each sentence to make consistent length."
      ]
    },
    {
      "metadata": {
        "id": "ItiJxkOu7sCw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import  sequence\n",
        "\n",
        "seq_len = 500\n",
        "\n",
        "trn = sequence.pad_sequences(trn, maxlen=seq_len, value=0)\n",
        "test = sequence.pad_sequences(test, maxlen=seq_len, value=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DebFUYwI7sC0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This results in nice rectangular matrices that can be passed to ML algorithms.   \n",
        "Reviews shorter than 500 words are pre-padded with zeros, those greater are truncated."
      ]
    },
    {
      "metadata": {
        "id": "JadheOYW7sC1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2508376-1058-4a07-dcc1-8b2e5e650678",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226187229,
          "user_tz": -330,
          "elapsed": 769,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "trn.shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "metadata": {
        "id": "h5tKezZk7sC4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create simple models"
      ]
    },
    {
      "metadata": {
        "id": "uHH0zUbL7sC5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Single hidden layer NN"
      ]
    },
    {
      "metadata": {
        "id": "k9r5NmsN7sC5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The simplest model that tends to give reasonable results is a single hidden layer net. [the dense.. fully connected layer ] \n",
        "*Note*:: that we can't expect to get any useful results by feeding word ids directly into a neural net   \n",
        "so instead we use an embedding to replace them with a vector of 32 (initially random) floats for each word in the vocab.  \n",
        "embedding..:: the vector of weights associated with an enitity"
      ]
    },
    {
      "metadata": {
        "id": "fpNgSrOGDWRI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Input\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.layers.convolutional import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dvk3UJFs7sC6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, 32, input_length=seq_len),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.7),\n",
        "    Dense(1, activation='sigmoid')])# op: positive or negative"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-nRoc_Y67sC9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "bb526333-86f2-4c12-dbfa-5f48e3724472",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226189778,
          "user_tz": -330,
          "elapsed": 791,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               1600100   \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,760,201\n",
            "Trainable params: 1,760,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "btpxWqvy7sDA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 36
            },
            {
              "item_id": 37
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "974970e5-35da-4fae-aa56-bec2b6475e31",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226204453,
          "user_tz": -330,
          "elapsed": 14600,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=2, batch_size=64)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 7s 278us/step - loss: 0.4640 - acc: 0.7540 - val_loss: 0.3022 - val_acc: 0.8718\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 7s 263us/step - loss: 0.1887 - acc: 0.9298 - val_loss: 0.3188 - val_acc: 0.8653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c6fca4dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "metadata": {
        "id": "xVeIXxHC7sDC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The [stanford paper](http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf) that this dataset is from cites a state of the art accuracy (without unlabelled data) of 0.883. So we're short of that, but on the right track."
      ]
    },
    {
      "metadata": {
        "id": "7NoD1izv7sDD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Single conv layer with max pooling"
      ]
    },
    {
      "metadata": {
        "id": "LsA_yZSt7sDE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A CNN is likely to work better, since it's designed to take advantage of ordered data.   \n",
        "We'll need to use a 1D CNN, since a sequence of words is 1D."
      ]
    },
    {
      "metadata": {
        "id": "80s6lxJd7sDE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "4609524c-2f37-4695-83d4-bdcedd823b31",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226205397,
          "user_tz": -330,
          "elapsed": 898,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "conv1 = Sequential([\n",
        "    Embedding(vocab_size, 32, input_length=seq_len, dropout=0.2),\n",
        "    Dropout(0.2),\n",
        "    Convolution1D(64, 5, border_mode='same', activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    MaxPooling1D(),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.7),\n",
        "    Dense(1, activation='sigmoid')])"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
            "  \n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 5, padding=\"same\", activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cr6aM3h57sDH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "conv1.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pE3TUSvl7sDL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 70
            },
            {
              "item_id": 96
            },
            {
              "item_id": 97
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "f9a637a3-58c4-4018-c590-a1312f1feada",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226244094,
          "user_tz": -330,
          "elapsed": 37780,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "conv1.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=4, batch_size=64)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 9s 373us/step - loss: 0.5049 - acc: 0.7239 - val_loss: 0.2816 - val_acc: 0.8798\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 9s 357us/step - loss: 0.2647 - acc: 0.9030 - val_loss: 0.2717 - val_acc: 0.8850\n",
            "Epoch 3/4\n",
            "20224/25000 [=======================>......] - ETA: 1s - loss: 0.2055 - acc: 0.9236"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 9s 355us/step - loss: 0.2080 - acc: 0.9223 - val_loss: 0.2627 - val_acc: 0.8897\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 9s 355us/step - loss: 0.1779 - acc: 0.9364 - val_loss: 0.2777 - val_acc: 0.8918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c0a766750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "metadata": {
        "id": "2Qf28xvJ7sDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "That's well past the Stanford paper's accuracy - another win for CNNs!\n",
        "amlost easy.. ht eordering and padding are judgement calls..?"
      ]
    },
    {
      "metadata": {
        "id": "W0zv-skW7sDU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "conv1.save_weights(model_path + 'conv1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ajt2A51w7sDZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "conv1.load_weights(model_path + 'conv1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BT0k_PwF7sDd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pre-trained vectors"
      ]
    },
    {
      "metadata": {
        "id": "qA7BKD3e7sDe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You may want to look at wordvectors.ipynb before moving on.\n",
        "\n",
        "In this section, we replicate the previous CNN, but using pre-trained embeddings."
      ]
    },
    {
      "metadata": {
        "id": "D68Vbgyh7sDe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def get_glove_dataset(dataset):\n",
        "    \"\"\"Download the requested glove dataset from files.fast.ai\n",
        "    and return a location that can be passed to load_vectors.\n",
        "    \"\"\"\n",
        "    # see wordvectors.ipynb for info on how these files were\n",
        "    # generated from the original glove data.\n",
        "    md5sums = {'6B.50d': '8e1557d1228decbda7db6dfd81cd9909',\n",
        "               '6B.100d': 'c92dbbeacde2b0384a43014885a60b2c',\n",
        "               '6B.200d': 'af271b46c04b0b2e41a84d8cd806178d',\n",
        "               '6B.300d': '30290210376887dcc6d0a5a6374d8255'}\n",
        "    glove_path = os.path.abspath('data/glove/results')\n",
        "    %mkdir -p $glove_path\n",
        "    return get_file(dataset,\n",
        "                    'http://files.fast.ai/models/glove/' + dataset + '.tgz',\n",
        "                    cache_subdir=glove_path,\n",
        "                    md5_hash=md5sums.get(dataset, None),\n",
        "                    untar=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OyXZJm1v7sDg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def load_vectors(loc):\n",
        "    return (load_array(loc+'.dat'),\n",
        "        pickle.load(open(loc+'_words.pkl','rb')),\n",
        "        pickle.load(open(loc+'_idx.pkl','rb')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nxqWUVkNLjzG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import bcolz\n",
        "def load_array(fname):\n",
        "    return bcolz.open(fname)[:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "seYxjI0p7sDi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vecs, words, wordidx = load_vectors(get_glove_dataset('6B.50d')) # observe the names in the cell above\n",
        "# cehck out the structure of the gove data set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bfJ_kQcIx0Ku",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65d33dcc-55cb-41e1-86f9-fd6e625ca482",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226653270,
          "user_tz": -330,
          "elapsed": 1098,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "type(vecs)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "metadata": {
        "id": "fmmH-KKJx3bZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "64959975-bd55-4629-dea2-ace3d743b669",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226719994,
          "user_tz": -330,
          "elapsed": 846,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vecs.view()"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.418   ,  0.24968 , -0.41242 , ..., -0.18411 , -0.11514 ,\n",
              "        -0.78581 ],\n",
              "       [ 0.013441,  0.23682 , -0.16899 , ..., -0.56657 ,  0.044691,\n",
              "         0.30392 ],\n",
              "       [ 0.15164 ,  0.30177 , -0.16763 , ..., -0.35652 ,  0.016413,\n",
              "         0.10216 ],\n",
              "       ...,\n",
              "       [-0.51181 ,  0.058706,  1.0913  , ..., -0.25003 , -1.125   ,\n",
              "         1.5863  ],\n",
              "       [-0.75898 , -0.47426 ,  0.4737  , ...,  0.78954 , -0.014116,\n",
              "         0.6448  ],\n",
              "       [ 0.072617, -0.51393 ,  0.4728  , ..., -0.18907 , -0.59021 ,\n",
              "         0.55559 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "metadata": {
        "id": "YR1xnYhRyJEV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7dea44e-9cc4-47c9-d9d6-56b793debfc9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226855266,
          "user_tz": -330,
          "elapsed": 825,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "isinstance(words, list)\n",
        "#isinstance(words[0], list)\n",
        "words[:10]"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "metadata": {
        "id": "EfkWcHqYytcG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "137d4e32-01a7-4408-901d-f07bd7bffe8b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522226966527,
          "user_tz": -330,
          "elapsed": 869,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "type(wordidx)\n",
        "#isinstance(wordidx, list)\n",
        "first2pairs = {k: wordidx[k] for k in wordidx.keys()[:2]}\n",
        "first2pairs"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'biennials': 130852, 'verplank': 42458}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "metadata": {
        "id": "zdvEvJ887sDq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The glove word ids and imdb word ids use different indexes.  \n",
        "\n",
        "create a simple function that creates an embedding matrix using the indexes from imdb, and the embeddings from glove (where they exist)."
      ]
    },
    {
      "metadata": {
        "id": "Q_depCeawz69",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import normal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_CgYeSN7sDq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_emb():\n",
        "    n_fact = vecs.shape[1]# number of factors\n",
        "    emb = np.zeros((vocab_size, n_fact)) # matrix of zeros:: emb\n",
        "\n",
        "    for i in range(1,len(emb)):\n",
        "        word = idx2word[i] # check for word in the idx2 word dict created above\n",
        "        if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word): # check that it is a word.. not some spl character junk\n",
        "            src_idx = wordidx[word] # wordidx is what we got from the glove data set\n",
        "            emb[i] = vecs[src_idx] # vecs is what we got from the glove datase/ embeddings\n",
        "        else:\n",
        "            # If we can't find the word in glove, randomly initialize # cool :)\n",
        "            emb[i] = normal(scale=0.6, size=(n_fact,))\n",
        "\n",
        "    # This is our \"rare word\" id - we want to randomly initialize\n",
        "    emb[-1] = normal(scale=0.6, size=(n_fact,))\n",
        "    emb/=3\n",
        "    return emb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NdQm1TK7sDs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "emb = create_emb()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RFdtRQ817sDt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We pass our embedding matrix to the Embedding constructor, and set it to non-trainable."
      ]
    },
    {
      "metadata": {
        "id": "s-oHvSxe7sDu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "07ff8607-7406-40f6-8a11-97aa6f21ed29",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522227014783,
          "user_tz": -330,
          "elapsed": 1199,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, 50, input_length=seq_len, dropout=0.2, \n",
        "              weights=[emb], trainable=False),\n",
        "    Dropout(0.25),\n",
        "    Convolution1D(64, 5, border_mode='same', activation='relu'),\n",
        "    Dropout(0.25),\n",
        "    MaxPooling1D(),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.7),\n",
        "    Dense(1, activation='sigmoid')])"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 5, padding=\"same\", activation=\"relu\")`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0mC9WdP97sDw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2itX2mR17sDy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 46
            },
            {
              "item_id": 47
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "cec1e296-9c48-4d51-9d10-d6ca96abe8de",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522227037529,
          "user_tz": -330,
          "elapsed": 19094,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=2, batch_size=64)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 9s 371us/step - loss: 0.6557 - acc: 0.5963 - val_loss: 0.5526 - val_acc: 0.7247\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 9s 342us/step - loss: 0.5293 - acc: 0.7437 - val_loss: 0.4649 - val_acc: 0.7963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c0587b590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "metadata": {
        "id": "EUIrS0V37sD0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We already have beaten our previous model! But let's fine-tune the embedding weights - especially since the words we couldn't find in glove just have random embeddings."
      ]
    },
    {
      "metadata": {
        "id": "avhgGdRE7sD1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.layers[0].trainable=True #the embedding layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-XUWN-n07sD2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.optimizer.lr=1e-4 # very tiny LR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BiHqCFpN7sD5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 22
            },
            {
              "item_id": 23
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "41e425de-084f-4273-ec45-2badf5027a84",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522227175235,
          "user_tz": -330,
          "elapsed": 9381,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=1, batch_size=64)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/1\n",
            "25000/25000 [==============================] - 9s 342us/step - loss: 0.4468 - acc: 0.7994 - val_loss: 0.4131 - val_acc: 0.8236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c0a8b1e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "metadata": {
        "id": "QQ8rk7Ki7sD7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As expected, that's given us a nice little boost. :) From what was 79 .. to 81 on the validation set"
      ]
    },
    {
      "metadata": {
        "id": "u56I-B_J7sD7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(model_path+'glove50.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "huiq0a1q7sED",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi-size CNN"
      ]
    },
    {
      "metadata": {
        "id": "ZNutD8Rl7sEE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is an implementation of a multi-size CNN as shown in Ben Bowles' [excellent blog post](https://quid.com/feed/how-quid-uses-deep-learning-with-small-data)."
      ]
    },
    {
      "metadata": {
        "id": "TX8JqmDZ7sEE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Merge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozqbzNce7sEH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use the functional API to create multiple conv layers of different sizes, and then concatenate them."
      ]
    },
    {
      "metadata": {
        "id": "2XwJWXNJ7sEI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "e94ab2fb-4279-48b8-8d83-2193e4f1d91f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522227196346,
          "user_tz": -330,
          "elapsed": 958,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "graph_in = Input ((vocab_size, 50))\n",
        "convs = [ ] \n",
        "for fsz in range (3, 6): \n",
        "    x = Convolution1D(64, fsz, border_mode='same', activation=\"relu\")(graph_in)\n",
        "    x = MaxPooling1D()(x) \n",
        "    x = Flatten()(x) \n",
        "    convs.append(x)\n",
        "out = Merge(mode=\"concat\")(convs) \n",
        "graph = Model(graph_in, out) "
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 3, padding=\"same\", activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 4, padding=\"same\", activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 5, padding=\"same\", activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HykpQ1uD7sEL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "emb = create_emb()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hrjYlQVa7sEM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We then replace the conv/max-pool layer in our original CNN with the concatenated conv layers.  \n",
        "find out what the graph layer does..?"
      ]
    },
    {
      "metadata": {
        "id": "PXajBkKK7sEN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7fd7c824-cef9-4bb7-9f12-6eb907b0d66c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522227200990,
          "user_tz": -330,
          "elapsed": 1172,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential ([\n",
        "    Embedding(vocab_size, 50, input_length=seq_len, dropout=0.2, weights=[emb]),\n",
        "    Dropout (0.2),\n",
        "    graph,\n",
        "    Dropout (0.5),\n",
        "    Dense (100, activation=\"relu\"),\n",
        "    Dropout (0.7),\n",
        "    Dense (1, activation='sigmoid')\n",
        "    ])"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "A8b2p6ZU7sES",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-icRF16g7sEU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 107
            },
            {
              "item_id": 108
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "e94bd90b-1150-4a5f-95c9-4009b2ed0ec4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522227246797,
          "user_tz": -330,
          "elapsed": 43370,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=2, batch_size=64)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 21s 848us/step - loss: 0.6521 - acc: 0.5777 - val_loss: 0.3821 - val_acc: 0.8404\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 20s 813us/step - loss: 0.3424 - acc: 0.8572 - val_loss: 0.2629 - val_acc: 0.8930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c04ac7190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "metadata": {
        "id": "W6ZvkWiL7sEa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Interestingly, I found that in this case I got best results when I started the embedding layer as being trainable,  \n",
        "and then set it to non-trainable after a couple of epochs. I have no idea why!\n",
        "\n",
        "(2 runs of training accuracy goes form 81 to 81.. set the embedding trainable.. accuracy is at 89)\n",
        "\n",
        "Same here jeremy :P"
      ]
    },
    {
      "metadata": {
        "id": "q0plNsAy7sEb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.layers[0].trainable=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CyR9emkX7sEc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.optimizer.lr=1e-5# even smaller LR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RQlQsBFY7sEg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 103
            },
            {
              "item_id": 104
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "63fb7fd8-270d-4d94-afe0-cbbb1eac35bd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522227352378,
          "user_tz": -330,
          "elapsed": 41516,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=2, batch_size=64)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 20s 814us/step - loss: 0.2605 - acc: 0.9020 - val_loss: 0.2635 - val_acc: 0.8918\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 20s 812us/step - loss: 0.2219 - acc: 0.9178 - val_loss: 0.2606 - val_acc: 0.8958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c0a8b6750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "metadata": {
        "id": "Q4QbMCpL7sEl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This more complex architecture has given us another boost in accuracy.\n",
        "proposal.. run experiments to see if the embedding layer being set to trainable.. boosts the accuracy..  \n",
        "or it is just a consequence of training the entrie stack again..?"
      ]
    },
    {
      "metadata": {
        "id": "em73CSA27sEl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*italicized text*## LSTM\n",
        "\n",
        "LSTM much mordern.. such wow.. :)"
      ]
    },
    {
      "metadata": {
        "id": "v7my0BQK7sEm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We haven't covered this bit yet!"
      ]
    },
    {
      "metadata": {
        "id": "VyGoxNJh2iKZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.regularizers import l2\n",
        "from keras.layers import  LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K28ealcF7sEn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "9fd74803-42a1-407c-c843-2cbae9ccab18",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522227919834,
          "user_tz": -330,
          "elapsed": 842,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, 32, input_length=seq_len, mask_zero=True,\n",
        "              W_regularizer=l2(1e-6), dropout=0.2),\n",
        "    LSTM(100, consume_less='gpu'),\n",
        "    Dense(1, activation='sigmoid')])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary() # one embedding layer.. onle LSTM layer.. for retaining.. memory about the order in which things come in..\n",
        "#and a dense/ fully connected layer.. 1 output"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(5000, 32, mask_zero=True, embeddings_regularizer=<keras.reg..., input_length=500)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(100, implementation=2)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5vXXAwI7sEt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 545
            },
            {
              "item_id": 1141
            },
            {
              "item_id": 1594
            },
            {
              "item_id": 1960
            },
            {
              "item_id": 1961
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "64721535-5400-4d2f-eed1-d228bd9f68ed",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522231110212,
          "user_tz": -330,
          "elapsed": 3125350,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(trn, labels_train, validation_data=(test, labels_test), nb_epoch=5, batch_size=64)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/5\n",
            "25000/25000 [==============================] - 630s 25ms/step - loss: 0.4581 - acc: 0.7695 - val_loss: 0.3280 - val_acc: 0.8642\n",
            "Epoch 2/5\n",
            " 9728/25000 [==========>...................] - ETA: 4:54 - loss: 0.2954 - acc: 0.8847"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 630s 25ms/step - loss: 0.2849 - acc: 0.8865 - val_loss: 0.3328 - val_acc: 0.8614\n",
            "Epoch 3/5\n",
            "22784/25000 [==========================>...] - ETA: 42s - loss: 0.2422 - acc: 0.9067"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 629s 25ms/step - loss: 0.2414 - acc: 0.9066 - val_loss: 0.3571 - val_acc: 0.8635\n",
            "Epoch 4/5\n",
            "25000/25000 [==============================] - 634s 25ms/step - loss: 0.2230 - acc: 0.9156 - val_loss: 0.3327 - val_acc: 0.8732\n",
            "Epoch 5/5\n",
            " 1600/25000 [>.............................] - ETA: 6:59 - loss: 0.1739 - acc: 0.9375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 600s 24ms/step - loss: 0.1876 - acc: 0.9291 - val_loss: 0.3598 - val_acc: 0.8758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c01be0b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "metadata": {
        "id": "2ejE7TiZ2-q9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "LSTM takes time to train.. 1 epoch is about 8 mins to start with..   \n",
        "5\\*8 40 mins.. around :)   \n",
        "Subsequent layers take lesser time..?"
      ]
    },
    {
      "metadata": {
        "id": "5bwslwy67sEw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9df1deea-5567-4221-c04b-6a9711b87966",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522231110849,
          "user_tz": -330,
          "elapsed": 615,
          "user": {
            "displayName": "Rony Roy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111772801988052207421"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "2+2"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    }
  ]
}